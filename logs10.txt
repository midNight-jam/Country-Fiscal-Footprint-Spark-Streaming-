
========= 2016-12-12 12:46:52 =========
-------------------------------------------
Time: 2016-12-12 12:46:53
-------------------------------------------

========= 2016-12-12 12:46:53 =========
-------------------------------------------
Time: 2016-12-12 12:46:54
-------------------------------------------

========= 2016-12-12 12:46:54 =========
-------------------------------------------
Time: 2016-12-12 12:46:55
-------------------------------------------

========= 2016-12-12 12:46:55 =========
========= 2016-12-12 12:46:56 =========
Traceback (most recent call last):
  File "/home/jayam/PycharmProjects/FirstSpark/Stream2.py", line 57, in <module>
    ssc.awaitTermination()
  File "/usr/local/spark/python/lib/pyspark.zip/pyspark/streaming/context.py", line 206, in awaitTermination
  File "/usr/local/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
  File "/usr/local/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 63, in deco
  File "/usr/local/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
py4j.protocol.Py4JJavaError: An error occurred while calling o26.awaitTermination.
: org.apache.spark.SparkException: An exception was raised by Python:
Traceback (most recent call last):
  File "/usr/local/spark/python/lib/pyspark.zip/pyspark/streaming/util.py", line 65, in call
    r = self.func(t, *rdds)
  File "/usr/local/spark/python/lib/pyspark.zip/pyspark/streaming/dstream.py", line 171, in takeAndPrint
    taken = rdd.take(num + 1)
  File "/usr/local/spark/python/lib/pyspark.zip/pyspark/rdd.py", line 1310, in take
    res = self.context.runJob(self, takeUpToNumLeft, p)
  File "/usr/local/spark/python/lib/pyspark.zip/pyspark/context.py", line 941, in runJob
    port = self._jvm.PythonRDD.runJob(self._jsc.sc(), mappedRDD._jrdd, partitions)
  File "/usr/local/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 933, in __call__
    answer, self.gateway_client, self.target_id, self.name)
  File "/usr/local/spark/python/lib/pyspark.zip/pyspark/sql/utils.py", line 63, in deco
    return f(*a, **kw)
  File "/usr/local/spark/python/lib/py4j-0.10.1-src.zip/py4j/protocol.py", line 312, in get_return_value
    format(target_id, ".", name), value)
Py4JJavaError: An error occurred while calling z:org.apache.spark.api.python.PythonRDD.runJob.
: org.apache.spark.SparkException: Job aborted due to stage failure: Task 0 in stage 1.0 failed 1 times, most recent failure: Lost task 0.0 in stage 1.0 (TID 1, localhost): org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py", line 172, in main
    process()
  File "/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py", line 167, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 263, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/home/jayam/PycharmProjects/FirstSpark/Stream2.py", line 28, in <lambda>
    words = kvs.flatMap(lambda line: line.split(","))
AttributeError: 'tuple' object has no attribute 'split'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

Driver stacktrace:
	at org.apache.spark.scheduler.DAGScheduler.org$apache$spark$scheduler$DAGScheduler$$failJobAndIndependentStages(DAGScheduler.scala:1450)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1438)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$abortStage$1.apply(DAGScheduler.scala:1437)
	at scala.collection.mutable.ResizableArray$class.foreach(ResizableArray.scala:59)
	at scala.collection.mutable.ArrayBuffer.foreach(ArrayBuffer.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.abortStage(DAGScheduler.scala:1437)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGScheduler$$anonfun$handleTaskSetFailed$1.apply(DAGScheduler.scala:811)
	at scala.Option.foreach(Option.scala:257)
	at org.apache.spark.scheduler.DAGScheduler.handleTaskSetFailed(DAGScheduler.scala:811)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.doOnReceive(DAGScheduler.scala:1659)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1618)
	at org.apache.spark.scheduler.DAGSchedulerEventProcessLoop.onReceive(DAGScheduler.scala:1607)
	at org.apache.spark.util.EventLoop$$anon$1.run(EventLoop.scala:48)
	at org.apache.spark.scheduler.DAGScheduler.runJob(DAGScheduler.scala:632)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1871)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1884)
	at org.apache.spark.SparkContext.runJob(SparkContext.scala:1897)
	at org.apache.spark.api.python.PythonRDD$.runJob(PythonRDD.scala:441)
	at org.apache.spark.api.python.PythonRDD.runJob(PythonRDD.scala)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:237)
	at py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)
	at py4j.Gateway.invoke(Gateway.java:280)
	at py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:128)
	at py4j.commands.CallCommand.execute(CallCommand.java:79)
	at py4j.GatewayConnection.run(GatewayConnection.java:211)
	at java.lang.Thread.run(Thread.java:745)
Caused by: org.apache.spark.api.python.PythonException: Traceback (most recent call last):
  File "/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py", line 172, in main
    process()
  File "/usr/local/spark/python/lib/pyspark.zip/pyspark/worker.py", line 167, in process
    serializer.dump_stream(func(split_index, iterator), outfile)
  File "/usr/local/spark/python/lib/pyspark.zip/pyspark/serializers.py", line 263, in dump_stream
    vs = list(itertools.islice(iterator, batch))
  File "/home/jayam/PycharmProjects/FirstSpark/Stream2.py", line 28, in <lambda>
    words = kvs.flatMap(lambda line: line.split(","))
AttributeError: 'tuple' object has no attribute 'split'

	at org.apache.spark.api.python.PythonRunner$$anon$1.read(PythonRDD.scala:193)
	at org.apache.spark.api.python.PythonRunner$$anon$1.<init>(PythonRDD.scala:234)
	at org.apache.spark.api.python.PythonRunner.compute(PythonRDD.scala:152)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.api.python.PythonRDD.compute(PythonRDD.scala:63)
	at org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:319)
	at org.apache.spark.rdd.RDD.iterator(RDD.scala:283)
	at org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:70)
	at org.apache.spark.scheduler.Task.run(Task.scala:85)
	at org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:274)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	... 1 more


	at org.apache.spark.streaming.api.python.TransformFunction.callPythonTransformFunction(PythonDStream.scala:92)
	at org.apache.spark.streaming.api.python.TransformFunction.apply(PythonDStream.scala:75)
	at org.apache.spark.streaming.api.python.PythonDStream$$anonfun$callForeachRDD$1.apply(PythonDStream.scala:176)
	at org.apache.spark.streaming.api.python.PythonDStream$$anonfun$callForeachRDD$1.apply(PythonDStream.scala:176)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply$mcV$sp(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1$$anonfun$apply$mcV$sp$1.apply(ForEachDStream.scala:51)
	at org.apache.spark.streaming.dstream.DStream.createRDDWithLocalProperties(DStream.scala:415)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply$mcV$sp(ForEachDStream.scala:50)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:50)
	at org.apache.spark.streaming.dstream.ForEachDStream$$anonfun$1.apply(ForEachDStream.scala:50)
	at scala.util.Try$.apply(Try.scala:192)
	at org.apache.spark.streaming.scheduler.Job.run(Job.scala:39)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply$mcV$sp(JobScheduler.scala:245)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:245)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler$$anonfun$run$1.apply(JobScheduler.scala:245)
	at scala.util.DynamicVariable.withValue(DynamicVariable.scala:58)
	at org.apache.spark.streaming.scheduler.JobScheduler$JobHandler.run(JobScheduler.scala:244)
	at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1142)
	at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:617)
	at java.lang.Thread.run(Thread.java:745)

-------------------------------------------
Time: 2016-12-12 12:48:45
-------------------------------------------

Time: 2016-12-12 12:49:01
-------------------------------------------
{"schema":{"type":"string","optional":false},"payload":"AUT,Austria,TLYCG,Total government expenditure,010,General public services,GS13,General government,C,Current prices,2010,2010,EUR,Euro,6,Millions,,,888.88,,"}

========= 2016-12-12 12:49:01 =========
+--------------------+-----+
|                word|total|
+--------------------+-----+
|{"schema":{"type"...|    1|
+--------------------+-----+

-------------------------------------------
Time: 2016-12-12 12:49:02
-------------------------------------------
========= 2016-12-12 12:58:24 =========
-------------------------------------------
Time: 2016-12-12 12:58:25
-------------------------------------------
{"schema":{"type":"string","optional":false},"payload":"AUT,Austria,TLYCG,Total government expenditure,010,General public services,GS13,General government,C,Current prices,2010,2010,EUR,Euro,6,Millions,,,666.66,,"}

========= 2016-12-12 12:58:25 =========
+--------------------+-----+
|                word|total|
+--------------------+-----+
|{"schema":{"type"...|    1|
+--------------------+-----+

-------------------------------------------

-------------------------------------------
Time: 2016-12-12 13:08:53
-------------------------------------------

========= 2016-12-12 13:08:53 =========
-------------------------------------------
Time: 2016-12-12 13:08:54
-------------------------------------------

========= 2016-12-12 13:08:54 =========
-------------------------------------------
Time: 2016-12-12 13:08:55
-------------------------------------------
{"schema":{"type":"string","optional":false},"payload":"AUT,Austria,TLYCG,Total government expenditure,010,General public services,GS13,General government,C,Current prices,2010,2010,EUR,Euro,6,Millions,,,666.66,,"}

========= 2016-12-12 13:08:55 =========
-------------------------------------------
Time: 2016-12-12 13:08:56
-------------------------------------------

========= 2016-12-12 13:08:56 =========
-------------------------------------------
Time: 2016-12-12 13:08:57
-------------------------------------------

========= 2016-12-12 13:08:57 =========
-------------------------------------------
Time: 2016-12-12 13:08:58
-------------------------------------------

========= 2016-12-12 13:08:58 =========
-------------------------------------------
Time: 2016-12-12 13:08:59
-------------------------------------------

========= 2016-12-12 13:08:59 =========
-------------------------------------------
Time: 2016-12-12 13:09:00
-------------------------------------------

========= 2016-12-12 13:09:00 =========
-------------------------------------------
Time: 2016-12-12 13:09:01
-------------------------------------------
{"schema":{"type":"string","optional":false},"payload":"AUT,Austria,TLYCG,Total government expenditure,010,General public services,GS13,General government,C,Current prices,2010,2010,EUR,Euro,6,Millions,,,666.66,,"}

========= 2016-12-12 13:09:01 =========
-------------------------------------------
Time: 2016-12-12 13:09:02
-------------------------------------------

========= 2016-12-12 13:09:02 =========
-------------------------------------------
Time: 2016-12-12 13:09:03
-------------------------------------------

========= 2016-12-12 13:09:03 =========
-------------------------------------------
Time: 2016-12-12 13:09:04
-------------------------------------------

========= 2016-12-12 13:09:04 =========
-------------------------------------------
Time: 2016-12-12 13:09:05
-------------------------------------------

========= 2016-12-12 13:09:05 =========
-------------------------------------------
Time: 2016-12-12 13:09:06
-------------------------------------------

========= 2016-12-12 13:09:06 =========
-------------------------------------------
Time: 2016-12-12 13:09:07
-------------------------------------------

========= 2016-12-12 13:09:07 =========
-------------------------------------------
Time: 2016-12-12 13:09:08
-------------------------------------------

========= 2016-12-12 13:09:08 =========
-------------------------------------------
Time: 2016-12-12 13:09:09
-------------------------------------------

========= 2016-12-12 13:09:09 =========
-------------------------------------------
Time: 2016-12-12 13:09:10
-------------------------------------------

========= 2016-12-12 13:09:10 =========
-------------------------------------------
Time: 2016-12-12 13:09:11
-------------------------------------------

========= 2016-12-12 13:09:11 =========
-------------------------------------------
Time: 2016-12-12 13:09:12
-------------------------------------------

========= 2016-12-12 13:09:12 =========
-------------------------------------------
Time: 2016-12-12 13:09:13
-------------------------------------------

========= 2016-12-12 13:09:13 =========
-------------------------------------------
Time: 2016-12-12 13:09:14
-------------------------------------------

========= 2016-12-12 13:09:14 =========
-------------------------------------------
Time: 2016-12-12 13:09:15
-------------------------------------------

========= 2016-12-12 13:09:15 =========
-------------------------------------------
Time: 2016-12-12 13:09:16
-------------------------------------------

========= 2016-12-12 13:09:16 =========
-------------------------------------------
Time: 2016-12-12 13:09:17
-------------------------------------------

========= 2016-12-12 13:09:17 =========
-------------------------------------------
Time: 2016-12-12 13:09:18
-------------------------------------------

========= 2016-12-12 13:09:18 =========
-------------------------------------------
Time: 2016-12-12 13:09:19
-------------------------------------------

========= 2016-12-12 13:09:19 =========
-------------------------------------------
Time: 2016-12-12 13:09:20
-------------------------------------------

========= 2016-12-12 13:09:20 =========
-------------------------------------------
Time: 2016-12-12 13:09:21
-------------------------------------------

========= 2016-12-12 13:09:21 =========
-------------------------------------------
Time: 2016-12-12 13:09:22
-------------------------------------------

========= 2016-12-12 13:09:22 =========
-------------------------------------------
Time: 2016-12-12 13:09:23
-------------------------------------------

========= 2016-12-12 13:09:23 =========
-------------------------------------------
Time: 2016-12-12 13:09:24
-------------------------------------------

========= 2016-12-12 13:09:24 =========
-------------------------------------------
Time: 2016-12-12 13:09:25
-------------------------------------------

========= 2016-12-12 13:09:25 =========
-------------------------------------------
Time: 2016-12-12 13:09:26
-------------------------------------------

========= 2016-12-12 13:09:26 =========
-------------------------------------------
Time: 2016-12-12 13:09:27
-------------------------------------------

========= 2016-12-12 13:09:27 =========
-------------------------------------------
Time: 2016-12-12 13:09:28
-------------------------------------------

========= 2016-12-12 13:09:28 =========
-------------------------------------------
Time: 2016-12-12 13:09:29
-------------------------------------------

========= 2016-12-12 13:09:29 =========
-------------------------------------------
Time: 2016-12-12 13:09:30
-------------------------------------------

========= 2016-12-12 13:09:30 =========
-------------------------------------------
Time: 2016-12-12 13:09:31
-------------------------------------------

========= 2016-12-12 13:09:31 =========
-------------------------------------------
Time: 2016-12-12 13:09:32
-------------------------------------------

========= 2016-12-12 13:09:32 =========
-------------------------------------------
Time: 2016-12-12 13:09:33
-------------------------------------------

========= 2016-12-12 13:09:33 =========
-------------------------------------------
Time: 2016-12-12 13:09:34
-------------------------------------------

========= 2016-12-12 13:09:34 =========
-------------------------------------------
Time: 2016-12-12 13:09:35
-------------------------------------------

========= 2016-12-12 13:09:35 =========
-------------------------------------------
Time: 2016-12-12 13:09:36
-------------------------------------------

========= 2016-12-12 13:09:36 =========
Traceback (most recent call last):
  File "/home/jayam/PycharmProjects/FirstSpark/Stream2.py", line 59, in <module>
    ssc.awaitTermination()
  File "/usr/local/spark/python/lib/pyspark.zip/pyspark/streaming/context.py", line 206, in awaitTermination
  File "/usr/local/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 931, in __call__
  File "/usr/local/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 695, in send_command
  File "/usr/local/spark/python/lib/py4j-0.10.1-src.zip/py4j/java_gateway.py", line 828, in send_command
  File "/usr/lib/python2.7/socket.py", line 451, in readline
    data = self._sock.recv(self._rbufsize)
  File "/usr/local/spark/python/lib/pyspark.zip/pyspark/context.py", line 223, in signal_handler
KeyboardInterrupt
